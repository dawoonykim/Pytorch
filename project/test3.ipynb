{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 범퍼 데이터 갯수 안맞음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bumper_path = pd.read_csv(\"./data/data/source_data/bumper/bumper_path.csv\")\n",
    "# bumper_label = pd.read_csv(\"./data/data/label_data/bumper/bumper_label.csv\")\n",
    "\n",
    "# print(f\"{bumper_path},{bumper_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범퍼 데이터 병합 후 개수 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bumper_data = pd.read_csv(\"./data/data/output/bumper/bumper_data.csv\")\n",
    "# print(f\"Number of rows in CSV: {len(bumper_data)}\")\n",
    "# # print(df.duplicated().sum())  # 중복 행 개수 확인\n",
    "\n",
    "# bumper_data = bumper_data.drop_duplicates()\n",
    "# bumper_data.to_csv(\"./data/data/output/bumper/bumper_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 도어 데이터 갯수 안맞음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# door_path = pd.read_csv(\"./data/data/source_data/door/door_scratch_path.csv\")\n",
    "# door_label = pd.read_csv(\"./data/data/label_data/door/door_scratch_label.csv\")\n",
    "\n",
    "# print(f\"{door_path},{door_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도어 데이터 병합 후 개수 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in CSV: 1060\n"
     ]
    }
   ],
   "source": [
    "door_data = pd.read_csv(\"./data/data/output/door/door_scratch_data.csv\")\n",
    "print(f\"Number of rows in CSV: {len(door_data)}\")\n",
    "# print(df.duplicated().sum())  # 중복 행 개수 확인\n",
    "\n",
    "# door_data = door_data.drop_duplicates()\n",
    "# door_data.to_csv(\n",
    "#     \"./data/data/output/door/door_scratch_data.csv\", index=False)\n",
    "\n",
    "# print(door_data.iloc[:, 0])\n",
    "# print(door_data.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = door_data.iloc[:, 0].tolist()  # 첫 번째 열: 이미지 경로\n",
    "labels = door_data.iloc[:, 1].tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060\n",
      "1060\n"
     ]
    }
   ],
   "source": [
    "print(len(paths))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 정의\n",
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         # conv 2번 / pooling 2번 / ReLU 1번\n",
    "#         self.conv_Layers = nn.Sequential(\n",
    "#             # 32 - 5 + 1 -> 28 => 32 * 32를 28 * 28 * 6 사이즈로 변환\n",
    "#             nn.Conv2d(3, 6, 5),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),  # stride -> 28 * 28 => 14 * 14\n",
    "#             nn.Conv2d(6, 16, 5),  # 14 - 5 + 1 = 10 -> 14 * 14 => 10 * 10\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2)  # stride -> 10 * 10 => 5 * 5\n",
    "#         )\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc_layer = nn.Sequential(\n",
    "#             nn.Linear(5*5*16, 120),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(120, 84),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(84, 10)\n",
    "#         )  # fully connected layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.conv_Layers(x)\n",
    "#         flatten = self.flatten(out)\n",
    "#         fc_out = self.fc_layer(flatten)\n",
    "#         return fc_out\n",
    "\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = SimpleCNN()\n",
    "# model.to(device)\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLikeCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResNetLikeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetLikeCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # 3x3 Conv\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer (10 classes)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)  # Batch Normalization\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.batchnorm2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.batchnorm3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 4 * 4)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ResNetLikeCNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 정의\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# # 가중치 학습1\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# 가중치 학습2\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "# 가중치 학습3\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,\n",
    "#                       momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "# 가중치 학습 4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# 데이터셋 클래스 정의 (커스텀 데이터셋)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# 데이터 전처리 (Normalization 및 그레이스케일 변환)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # 그레이스케일로 변환 후 3채널로 확장\n",
    "    transforms.RandomHorizontalFlip(),  # 데이터 증강 : 이미지 좌우 반전\n",
    "    transforms.RandomCrop(32, padding=4),  # 데이터 증강 : padding 4 후 32*32로 랜덤 크롭\n",
    "    transforms.ToTensor(),  # 텐서로 변환\n",
    "    transforms.RandomRotation(10),  # 10도 회전\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # 밝기 및 대비 조정\n",
    "\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 정규화\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# CustomDataset으로 데이터셋 만들기\n",
    "train_dataset = CustomDataset(\n",
    "    image_paths=paths, labels=labels, transform=transform)\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# test_dataset = CustomDataset(\n",
    "#     image_paths=source_test_files, labels=test_json_dataset, transform=transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dawoo\\Desktop\\SF7\\coding\\PYTORCH\\pytorch-env\\Lib\\site-packages\\PIL\\Image.py:3186: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7903274139937233\n",
      "Epoch 2, Loss: 0.7014334605020636\n",
      "Epoch 3, Loss: 0.6918510426493252\n",
      "Epoch 4, Loss: 0.6976956251789542\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageFile, UnidentifiedImageError\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 손상된 이미지를 처리하도록 설정\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 손상된 이미지가 있으면 건너뛰기\n",
    "def safe_load_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image.load()  # 이미지가 제대로 로드되는지 확인\n",
    "        return image\n",
    "    except (OSError, UnidentifiedImageError, ValueError):\n",
    "        print(f\"Skipping corrupted image: {image_path}\")\n",
    "        return None  # 손상된 이미지는 None 반환\n",
    "\n",
    "# 데이터셋 클래스 정의 (커스텀 데이터셋)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "\n",
    "        for img_path, label in zip(image_paths, labels):\n",
    "            # 이미지 로드 및 유효성 확인\n",
    "            image = safe_load_image(img_path)\n",
    "            if image is not None:\n",
    "                self.data.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "\n",
    "        # 이미지를 다시 안전하게 로드\n",
    "        image = safe_load_image(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):  # train_loader에서 가져오기\n",
    "        # 손상된 이미지가 반환된 경우 건너뛰기\n",
    "        if inputs is None:\n",
    "            continue\n",
    "        \n",
    "        # 입력 데이터와 레이블을 device로 이동\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # 모델에 입력\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 학습률 스케줄러 업데이트\n",
    "    # scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"학습 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 테스트하기\n",
    "# correct = 0\n",
    "# total = len(test_loader.dataset)\n",
    "# with torch.no_grad():  # test는 기울기 계산 X\n",
    "#     for (images, labels) in test_loader:\n",
    "#         # 손상된 이미지가 반환된 경우 건너뛰기\n",
    "#         if images is None:\n",
    "#             continue\n",
    "        \n",
    "#         images, labels = images.to(device), labels.to(device)  # 이미지를 GPU로 이동\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f\"Accuracy: {100 * correct / total}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
