{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 폴더의 모든 파일 가져오기\n",
    "def get_all_files(directory):\n",
    "    all_files = []\n",
    "    for root, _, files in os.walk(directory):  # 하위 디렉토리 포함 탐색\n",
    "        for file in files:\n",
    "            all_files.append(os.path.join(root, file))  # 전체 경로 추가\n",
    "    return all_files\n",
    "\n",
    "\n",
    "# 예시 사용\n",
    "folder_path = '.\\\\data\\\\Radiator_grille\\\\1.Training\\\\source\\\\Radiator_grille\\\\gap'  # 대상 폴더 경로\n",
    "source_files = get_all_files(folder_path)\n",
    "\n",
    "\n",
    "# JSON 파일들이 저장된 폴더\n",
    "label_path = \".\\\\data\\\\Radiator_grille\\\\1.Training\\\\labeling\\\\Radiator_grille\\\\gap\"\n",
    "source_labels = get_all_files(label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "forder_test_path = \".\\\\data\\\\Radiator_grille\\\\2.Validation\\\\source\\\\Radiator_grille\\\\gap\"\n",
    "source_test_files = get_all_files(forder_test_path)\n",
    "label_test_path= \".\\\\data\\\\Radiator_grille\\\\2.Validation\\\\labeling\\\\Radiator_grille\\\\gap\"\n",
    "source_test_labels = get_all_files(label_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 정의\n",
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         # conv 2번 / pooling 2번 / ReLU 1번\n",
    "#         self.conv_Layers = nn.Sequential(\n",
    "#             # 32 - 5 + 1 -> 28 => 32 * 32를 28 * 28 * 6 사이즈로 변환\n",
    "#             nn.Conv2d(3, 6, 5),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2),  # stride -> 28 * 28 => 14 * 14\n",
    "#             nn.Conv2d(6, 16, 5),  # 14 - 5 + 1 = 10 -> 14 * 14 => 10 * 10\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2)  # stride -> 10 * 10 => 5 * 5\n",
    "#         )\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc_layer = nn.Sequential(\n",
    "#             nn.Linear(5*5*16, 120),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(120, 84),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(84, 10)\n",
    "#         )  # fully connected layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.conv_Layers(x)\n",
    "#         flatten = self.flatten(out)\n",
    "#         fc_out = self.fc_layer(flatten)\n",
    "#         return fc_out\n",
    "\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = SimpleCNN()\n",
    "# model.to(device)\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLikeCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResNetLikeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetLikeCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # 3x3 Conv\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer (10 classes)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)  # Batch Normalization\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.batchnorm2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.batchnorm3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 4 * 4)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ResNetLikeCNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋이 성공적으로 저장되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON 파일에서 'quality'를 숫자로 변환하는 매핑 예시\n",
    "quality_to_label = {\"불량품\": 0, \"양품\": 1}  # 예시로 매핑, 실제 데이터에 맞게 수정\n",
    "\n",
    "# 새로운 데이터셋을 저장할 리스트\n",
    "train_json_dataset = []\n",
    "\n",
    "for json_file in source_labels:\n",
    "    # JSON 파일 경로\n",
    "    json_path = json_file\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_path, 'r', encoding='utf-8-sig') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 필요한 데이터 추출\n",
    "    for annotation in data['annotations']:\n",
    "        # \"work\", \"part\", \"quality\" 데이터 추출\n",
    "        work = annotation['attributes'].get('work')\n",
    "        part = annotation['attributes'].get('part')\n",
    "        quality = annotation['attributes'].get('quality')\n",
    "\n",
    "        # 새로운 데이터셋 형식으로 저장\n",
    "        # train_json_dataset.append({\n",
    "        #     'work': work,\n",
    "        #     'part': part,\n",
    "        #     'quality': quality\n",
    "        # })\n",
    "\n",
    "        train_json_dataset.append(quality_to_label[quality])\n",
    "\n",
    "    # 추출된 데이터를 새로운 JSON 파일로 저장\n",
    "    # with open('extracted_dataset.json', 'w', encoding='utf-8') as f:\n",
    "    #     json.dump(train_json_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"학습 데이터셋이 성공적으로 저장되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터셋이 성공적으로 저장되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON 파일에서 'quality'를 숫자로 변환하는 매핑 예시\n",
    "quality_to_label = {\"불량품\": 0, \"양품\": 1}  # 예시로 매핑, 실제 데이터에 맞게 수정\n",
    "\n",
    "# 새로운 데이터셋을 저장할 리스트\n",
    "test_json_dataset = []\n",
    "\n",
    "for json_file in source_test_labels:\n",
    "    # JSON 파일 경로\n",
    "    json_path = json_file\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_path, 'r', encoding='utf-8-sig') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 필요한 데이터 추출\n",
    "    for annotation in data['annotations']:\n",
    "        # \"work\", \"part\", \"quality\" 데이터 추출\n",
    "        work = annotation['attributes'].get('work')\n",
    "        part = annotation['attributes'].get('part')\n",
    "        quality = annotation['attributes'].get('quality')\n",
    "\n",
    "        # 새로운 데이터셋 형식으로 저장\n",
    "        # train_json_dataset.append({\n",
    "        #     'work': work,\n",
    "        #     'part': part,\n",
    "        #     'quality': quality\n",
    "        # })\n",
    "\n",
    "        test_json_dataset.append(quality_to_label[quality])\n",
    "\n",
    "    # 추출된 데이터를 새로운 JSON 파일로 저장\n",
    "    # with open('extracted_dataset.json', 'w', encoding='utf-8') as f:\n",
    "    #     json.dump(train_json_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"테스트 데이터셋이 성공적으로 저장되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_json_dataset)\n",
    "# print(train_json_dataset.index(0))\n",
    "# print(train_json_dataset[train_json_dataset.index(0):])\n",
    "# print(source_files[train_json_dataset.index(0):])\n",
    "\n",
    "# print(test_json_dataset)\n",
    "# print(test_json_dataset.index(0))\n",
    "# print(test_json_dataset[test_json_dataset.index(0):])\n",
    "# print(source_test_labels[test_json_dataset.index(0):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = list(zip((source_files[train_json_dataset.index(\n",
    "#     \"불량품\"):]), train_json_dataset[train_json_dataset.index(\"불량품\"):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 정의\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# # 가중치 학습1\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# 가중치 학습2\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "# 가중치 학습3\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,\n",
    "#                       momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "# 가중치 학습 4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# 데이터셋 클래스 정의 (커스텀 데이터셋)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# 데이터 전처리 (Normalization 및 그레이스케일 변환)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # 그레이스케일로 변환 후 3채널로 확장\n",
    "    transforms.RandomHorizontalFlip(),  # 데이터 증강 : 이미지 좌우 반전\n",
    "    transforms.RandomCrop(32, padding=4),  # 데이터 증강 : padding 4 후 32*32로 랜덤 크롭\n",
    "    transforms.ToTensor(),  # 텐서로 변환\n",
    "    transforms.RandomRotation(10),  # 10도 회전\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # 밝기 및 대비 조정\n",
    "\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 정규화\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# CustomDataset으로 데이터셋 만들기\n",
    "train_dataset = CustomDataset(\n",
    "    image_paths=source_files, labels=train_json_dataset, transform=transform)\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    image_paths=source_test_files, labels=test_json_dataset, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile, UnidentifiedImageError\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 손상된 이미지를 처리하도록 설정\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 손상된 이미지가 있으면 건너뛰기\n",
    "def safe_load_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image.load()  # 이미지가 제대로 로드되는지 확인\n",
    "        return image\n",
    "    except (OSError, UnidentifiedImageError, ValueError):\n",
    "        print(f\"Skipping corrupted image: {image_path}\")\n",
    "        return None  # 손상된 이미지는 None 반환\n",
    "\n",
    "# 데이터셋 클래스 정의 (커스텀 데이터셋)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "\n",
    "        for img_path, label in zip(image_paths, labels):\n",
    "            # 이미지 로드 및 유효성 확인\n",
    "            image = safe_load_image(img_path)\n",
    "            if image is not None:\n",
    "                self.data.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "\n",
    "        # 이미지를 다시 안전하게 로드\n",
    "        image = safe_load_image(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):  # train_loader에서 가져오기\n",
    "        # 손상된 이미지가 반환된 경우 건너뛰기\n",
    "        if inputs is None:\n",
    "            continue\n",
    "        \n",
    "        # 입력 데이터와 레이블을 device로 이동\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # 모델에 입력\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 학습률 스케줄러 업데이트\n",
    "    # scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"학습 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.478134110787174%\n"
     ]
    }
   ],
   "source": [
    "# 테스트하기\n",
    "correct = 0\n",
    "total = len(test_loader.dataset)\n",
    "with torch.no_grad():  # test는 기울기 계산 X\n",
    "    for (images, labels) in test_loader:\n",
    "        # 손상된 이미지가 반환된 경우 건너뛰기\n",
    "        if images is None:\n",
    "            continue\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)  # 이미지를 GPU로 이동\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 폴더의 모든 파일 가져오기\n",
    "def get_all_files(directory):\n",
    "    all_files = []\n",
    "    for root, _, files in os.walk(directory):  # 하위 디렉토리 포함 탐색\n",
    "        for file in files:\n",
    "            all_files.append(os.path.join(root, file))  # 전체 경로 추가\n",
    "    return all_files\n",
    "\n",
    "\n",
    "# 예시 사용\n",
    "folder_path = '.\\\\data\\\\Radiator_grille\\\\1.Training\\\\source\\\\Radiator_grille\\\\gap'  # 대상 폴더 경로\n",
    "source_files = get_all_files(folder_path)\n",
    "\n",
    "\n",
    "# JSON 파일들이 저장된 폴더\n",
    "label_path = \".\\\\data\\\\Radiator_grille\\\\1.Training\\\\labeling\\\\Radiator_grille\\\\gap\"\n",
    "source_labels = get_all_files(label_path)\n",
    "\n",
    "# 모델 정의\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # conv 2번 / pooling 2번 / ReLU 1번\n",
    "        self.conv_Layers = nn.Sequential(\n",
    "            # 32 - 5 + 1 -> 28 => 32 * 32를 28 * 28 * 6 사이즈로 변환\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # stride -> 28 * 28 => 14 * 14\n",
    "            nn.Conv2d(6, 16, 5),  # 14 - 5 + 1 = 10 -> 14 * 14 => 10 * 10\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # stride -> 10 * 10 => 5 * 5\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(5*5*16, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )  # fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_Layers(x)\n",
    "        flatten = self.flatten(out)\n",
    "        fc_out = self.fc_layer(flatten)\n",
    "        return fc_out\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SimpleCNN()\n",
    "model.to(device)\n",
    "print(device)\n",
    "\n",
    "import json\n",
    "\n",
    "# JSON 파일에서 'quality'를 숫자로 변환하는 매핑 예시\n",
    "quality_to_label = {\"불량품\": 0, \"양품\": 1}  # 예시로 매핑, 실제 데이터에 맞게 수정\n",
    "\n",
    "# 새로운 데이터셋을 저장할 리스트\n",
    "train_json_dataset = []\n",
    "\n",
    "for json_file in source_labels:\n",
    "    # JSON 파일 경로\n",
    "    json_path = json_file\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_path, 'r', encoding='utf-8-sig') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 필요한 데이터 추출\n",
    "    for annotation in data['annotations']:\n",
    "        # \"work\", \"part\", \"quality\" 데이터 추출\n",
    "        work = annotation['attributes'].get('work')\n",
    "        part = annotation['attributes'].get('part')\n",
    "        quality = annotation['attributes'].get('quality')\n",
    "\n",
    "        # 새로운 데이터셋 형식으로 저장\n",
    "        # train_json_dataset.append({\n",
    "        #     'work': work,\n",
    "        #     'part': part,\n",
    "        #     'quality': quality\n",
    "        # })\n",
    "\n",
    "        train_json_dataset.append(quality_to_label[quality])\n",
    "\n",
    "    # 추출된 데이터를 새로운 JSON 파일로 저장\n",
    "    # with open('extracted_dataset.json', 'w', encoding='utf-8') as f:\n",
    "    #     json.dump(train_json_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"학습 데이터셋이 성공적으로 저장되었습니다!\")\n",
    "\n",
    "import json\n",
    "\n",
    "# JSON 파일에서 'quality'를 숫자로 변환하는 매핑 예시\n",
    "quality_to_label = {\"불량품\": 0, \"양품\": 1}  # 예시로 매핑, 실제 데이터에 맞게 수정\n",
    "\n",
    "# 새로운 데이터셋을 저장할 리스트\n",
    "test_json_dataset = []\n",
    "\n",
    "for json_file in source_test_labels:\n",
    "    # JSON 파일 경로\n",
    "    json_path = json_file\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_path, 'r', encoding='utf-8-sig') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 필요한 데이터 추출\n",
    "    for annotation in data['annotations']:\n",
    "        # \"work\", \"part\", \"quality\" 데이터 추출\n",
    "        work = annotation['attributes'].get('work')\n",
    "        part = annotation['attributes'].get('part')\n",
    "        quality = annotation['attributes'].get('quality')\n",
    "\n",
    "        # 새로운 데이터셋 형식으로 저장\n",
    "        # train_json_dataset.append({\n",
    "        #     'work': work,\n",
    "        #     'part': part,\n",
    "        #     'quality': quality\n",
    "        # })\n",
    "\n",
    "        test_json_dataset.append(quality_to_label[quality])\n",
    "\n",
    "    # 추출된 데이터를 새로운 JSON 파일로 저장\n",
    "    # with open('extracted_dataset.json', 'w', encoding='utf-8') as f:\n",
    "    #     json.dump(train_json_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"테스트 데이터셋이 성공적으로 저장되었습니다!\")\n",
    "\n",
    "# 손실함수 정의\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# # 가중치 학습1\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# 가중치 학습2\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "# 가중치 학습3\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# 데이터셋 클래스 정의 (커스텀 데이터셋)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# 데이터 전처리 (Normalization 및 그레이스케일 변환)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # 그레이스케일로 변환 후 3채널로 확장\n",
    "    transforms.RandomHorizontalFlip(),  # 데이터 증강 : 이미지 좌우 반전\n",
    "    transforms.RandomCrop(32, padding=4),  # 데이터 증강 : padding 4 후 32*32로 랜덤 크롭\n",
    "    transforms.ToTensor(),  # 텐서로 변환\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 정규화\n",
    "])\n",
    "\n",
    "# CustomDataset으로 데이터셋 만들기\n",
    "train_dataset = CustomDataset(\n",
    "    image_paths=source_files, labels=train_json_dataset, transform=transform)\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    image_paths=source_test_files, labels=test_json_dataset, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "from PIL import Image, ImageFile, UnidentifiedImageError\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 손상된 이미지를 처리하도록 설정\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 손상된 이미지가 있으면 건너뛰기\n",
    "def safe_load_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image.load()  # 이미지가 제대로 로드되는지 확인\n",
    "        return image\n",
    "    except (OSError, UnidentifiedImageError, ValueError):\n",
    "        print(f\"Skipping corrupted image: {image_path}\")\n",
    "        return None  # 손상된 이미지는 None 반환\n",
    "\n",
    "# 데이터셋 클래스 정의 (커스텀 데이터셋)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "\n",
    "        for img_path, label in zip(image_paths, labels):\n",
    "            # 이미지 로드 및 유효성 확인\n",
    "            image = safe_load_image(img_path)\n",
    "            if image is not None:\n",
    "                self.data.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "\n",
    "        # 이미지를 다시 안전하게 로드\n",
    "        image = safe_load_image(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):  # train_loader에서 가져오기\n",
    "        # 손상된 이미지가 반환된 경우 건너뛰기\n",
    "        if inputs is None:\n",
    "            continue\n",
    "        \n",
    "        # 입력 데이터와 레이블을 device로 이동\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # 모델에 입력\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 학습률 스케줄러 업데이트\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"학습 완료\")\n",
    "\n",
    "\n",
    "# 테스트하기\n",
    "correct = 0\n",
    "total = len(test_loader.dataset)\n",
    "with torch.no_grad():  # test는 기울기 계산 X\n",
    "    for (images, labels) in test_loader:\n",
    "        # 손상된 이미지가 반환된 경우 건너뛰기\n",
    "        if images is None:\n",
    "            continue\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)  # 이미지를 GPU로 이동\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수정코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 폴더의 모든 파일 가져오기\n",
    "def get_all_files(directory):\n",
    "    all_files = []\n",
    "    for root, _, files in os.walk(directory):  # 하위 디렉토리 포함 탐색\n",
    "        for file in files:\n",
    "            all_files.append(os.path.join(root, file))  # 전체 경로 추가\n",
    "    return all_files\n",
    "\n",
    "\n",
    "# 예시 사용\n",
    "folder_path = '.\\\\data\\\\Radiator_grille\\\\1.Training\\\\source\\\\Radiator_grille\\\\gap'  # 대상 폴더 경로\n",
    "source_files = get_all_files(folder_path)\n",
    "\n",
    "\n",
    "# JSON 파일들이 저장된 폴더\n",
    "label_path = \".\\\\data\\\\Radiator_grille\\\\1.Training\\\\labeling\\\\Radiator_grille\\\\gap\"\n",
    "source_labels = get_all_files(label_path)\n",
    "\n",
    "# 모델 정의\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResNetLikeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetLikeCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # 3x3 Conv\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer (10 classes)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)  # Batch Normalization\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.batchnorm2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.batchnorm3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 4 * 4)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ResNetLikeCNN()\n",
    "model.to(device)\n",
    "\n",
    "import json\n",
    "\n",
    "# JSON 파일에서 'quality'를 숫자로 변환하는 매핑 예시\n",
    "quality_to_label = {\"불량품\": 0, \"양품\": 1}  # 예시로 매핑, 실제 데이터에 맞게 수정\n",
    "\n",
    "# 새로운 데이터셋을 저장할 리스트\n",
    "train_json_dataset = []\n",
    "\n",
    "for json_file in source_labels:\n",
    "    # JSON 파일 경로\n",
    "    json_path = json_file\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_path, 'r', encoding='utf-8-sig') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 필요한 데이터 추출\n",
    "    for annotation in data['annotations']:\n",
    "        # \"work\", \"part\", \"quality\" 데이터 추출\n",
    "        work = annotation['attributes'].get('work')\n",
    "        part = annotation['attributes'].get('part')\n",
    "        quality = annotation['attributes'].get('quality')\n",
    "\n",
    "        # 새로운 데이터셋 형식으로 저장\n",
    "        # train_json_dataset.append({\n",
    "        #     'work': work,\n",
    "        #     'part': part,\n",
    "        #     'quality': quality\n",
    "        # })\n",
    "\n",
    "        train_json_dataset.append(quality_to_label[quality])\n",
    "\n",
    "    # 추출된 데이터를 새로운 JSON 파일로 저장\n",
    "    # with open('extracted_dataset.json', 'w', encoding='utf-8') as f:\n",
    "    #     json.dump(train_json_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"학습 데이터셋이 성공적으로 저장되었습니다!\")\n",
    "\n",
    "import json\n",
    "\n",
    "# JSON 파일에서 'quality'를 숫자로 변환하는 매핑 예시\n",
    "quality_to_label = {\"불량품\": 0, \"양품\": 1}  # 예시로 매핑, 실제 데이터에 맞게 수정\n",
    "\n",
    "# 새로운 데이터셋을 저장할 리스트\n",
    "test_json_dataset = []\n",
    "\n",
    "for json_file in source_test_labels:\n",
    "    # JSON 파일 경로\n",
    "    json_path = json_file\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_path, 'r', encoding='utf-8-sig') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 필요한 데이터 추출\n",
    "    for annotation in data['annotations']:\n",
    "        # \"work\", \"part\", \"quality\" 데이터 추출\n",
    "        work = annotation['attributes'].get('work')\n",
    "        part = annotation['attributes'].get('part')\n",
    "        quality = annotation['attributes'].get('quality')\n",
    "\n",
    "        # 새로운 데이터셋 형식으로 저장\n",
    "        # train_json_dataset.append({\n",
    "        #     'work': work,\n",
    "        #     'part': part,\n",
    "        #     'quality': quality\n",
    "        # })\n",
    "\n",
    "        test_json_dataset.append(quality_to_label[quality])\n",
    "\n",
    "    # 추출된 데이터를 새로운 JSON 파일로 저장\n",
    "    # with open('extracted_dataset.json', 'w', encoding='utf-8') as f:\n",
    "    #     json.dump(train_json_dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"테스트 데이터셋이 성공적으로 저장되었습니다!\")\n",
    "\n",
    "# 손실함수 정의\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# # 가중치 학습1\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# 가중치 학습2\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "# 가중치 학습3\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,\n",
    "#                       momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "# 가중치 학습4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "# 데이터셋 클래스 정의 (커스텀 데이터셋)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# 데이터 전처리 (Normalization 및 그레이스케일 변환)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # 그레이스케일로 변환 후 3채널로 확장\n",
    "    transforms.RandomHorizontalFlip(),  # 데이터 증강 : 이미지 좌우 반전\n",
    "    transforms.RandomCrop(32, padding=4),  # 데이터 증강 : padding 4 후 32*32로 랜덤 크롭\n",
    "    transforms.ToTensor(),  # 텐서로 변환\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 정규화\n",
    "])\n",
    "\n",
    "# CustomDataset으로 데이터셋 만들기\n",
    "train_dataset = CustomDataset(\n",
    "    image_paths=source_files, labels=train_json_dataset, transform=transform)\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    image_paths=source_test_files, labels=test_json_dataset, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "from PIL import Image, ImageFile, UnidentifiedImageError\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 손상된 이미지를 처리하도록 설정\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 손상된 이미지가 있으면 건너뛰기\n",
    "def safe_load_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image.load()  # 이미지가 제대로 로드되는지 확인\n",
    "        return image\n",
    "    except (OSError, UnidentifiedImageError, ValueError):\n",
    "        print(f\"Skipping corrupted image: {image_path}\")\n",
    "        return None  # 손상된 이미지는 None 반환\n",
    "\n",
    "# 데이터셋 클래스 정의 (커스텀 데이터셋)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "\n",
    "        for img_path, label in zip(image_paths, labels):\n",
    "            # 이미지 로드 및 유효성 확인\n",
    "            image = safe_load_image(img_path)\n",
    "            if image is not None:\n",
    "                self.data.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "\n",
    "        # 이미지를 다시 안전하게 로드\n",
    "        image = safe_load_image(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):  # train_loader에서 가져오기\n",
    "        # 손상된 이미지가 반환된 경우 건너뛰기\n",
    "        if inputs is None:\n",
    "            continue\n",
    "        \n",
    "        # 입력 데이터와 레이블을 device로 이동\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # 모델에 입력\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 학습률 스케줄러 업데이트\n",
    "    # scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"학습 완료\")\n",
    "\n",
    "\n",
    "# 테스트하기\n",
    "correct = 0\n",
    "total = len(test_loader.dataset)\n",
    "with torch.no_grad():  # test는 기울기 계산 X\n",
    "    for (images, labels) in test_loader:\n",
    "        # 손상된 이미지가 반환된 경우 건너뛰기\n",
    "        if images is None:\n",
    "            continue\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)  # 이미지를 GPU로 이동\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
