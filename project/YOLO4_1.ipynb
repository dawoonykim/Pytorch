{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 개수: 5904\n",
      "검증 데이터 개수: 1477\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 로드\n",
    "\n",
    "\n",
    "def load_data_with_pandas(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "data_bumper = load_data_with_pandas(\n",
    "    './data/data/output/bumper/bumper_data.csv')\n",
    "data_door_ed = load_data_with_pandas(\n",
    "    './data/data/output/door/door_ed_data.csv')\n",
    "data_door_scratch = load_data_with_pandas(\n",
    "    './data/data/output/door/door_scratch_data.csv')\n",
    "data_fender = load_data_with_pandas(\n",
    "    './data/data/output/fender/fender_ed_data.csv')\n",
    "data_frame_ed = load_data_with_pandas(\n",
    "    './data/data/output/frame/frame_ed_data.csv')\n",
    "data_frame_hd = load_data_with_pandas(\n",
    "    './data/data/output/frame/frame_hd_data.csv')\n",
    "data_frame_sealf = load_data_with_pandas(\n",
    "    './data/data/output/frame/frame_sealf_data.csv')\n",
    "data_frame_seamf = load_data_with_pandas(\n",
    "    './data/data/output/frame/frame_seamf_data.csv')\n",
    "\n",
    "# 데이터 결합\n",
    "data = pd.concat([\n",
    "    data_bumper,\n",
    "    data_door_ed,\n",
    "    data_door_scratch,\n",
    "    data_fender,\n",
    "    data_frame_ed,\n",
    "    data_frame_hd,\n",
    "    data_frame_sealf,\n",
    "    data_frame_seamf\n",
    "], axis=0)\n",
    "\n",
    "# data.to_csv('./data/data.csv', index=False)\n",
    "\n",
    "# 학습 데이터와 검증 데이터로 나누기 (Stratified Sampling)\n",
    "# y에는 라벨, x에는 나머지 특성 정보\n",
    "# x = data.drop('quality', axis=1)  # 'label' 컬럼은 실제 클래스 라벨이 들어있는 컬럼\n",
    "y = data['quality']\n",
    "\n",
    "# Stratified Split: 학습 데이터와 검증 데이터 비율을 80:20으로 설정, 클래스 비율을 유지\n",
    "train_data, valid_data = train_test_split(\n",
    "    data, test_size=0.2, stratify=y, random_state=35)\n",
    "\n",
    "# CSV로 저장\n",
    "train_data.to_csv('./data/train_data.csv', index=False)\n",
    "valid_data.to_csv('./data/valid_data.csv', index=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"학습 데이터 개수: {len(train_data)}\")\n",
    "print(f\"검증 데이터 개수: {len(valid_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 빈 리스트의 개수를 세는 코드\n",
    "# empty_bbox_count = sum(1 for bbox in train_data[\"bboxes\"] if bbox == '[]')\n",
    "\n",
    "# # 결과 출력\n",
    "# print(f\"빈 리스트의 개수: {empty_bbox_count}\")\n",
    "\n",
    "\n",
    "# # 리스트의 개수를 세는 코드\n",
    "# bbox_count = sum(1 for bbox in train_data[\"bboxes\"] if not bbox == '[]')\n",
    "\n",
    "# # 결과 출력\n",
    "# print(f\"리스트의 개수: {bbox_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ast\n",
    "# print(len(train_data))\n",
    "# 모든 bboxes 데이터 처리\n",
    "train_bboxes = []\n",
    "\n",
    "\n",
    "# 모든 bboxes 데이터 처리\n",
    "for bbox_str in train_data[\"bboxes\"]:\n",
    "    bboxes = ast.literal_eval(bbox_str)  # 문자열을 실제 리스트로 변환\n",
    "    bbox_list = []  # 해당 index에 대한 모든 bboxes를 저장할 리스트\n",
    "\n",
    "    # 각 bbox에 대해 처리\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        bbox_list.append([x, y, w, h])  # 해당 index의 모든 bbox를 하나의 리스트에 저장\n",
    "\n",
    "    # 하나의 index에 대한 bbox 리스트를 train_bboxes에 추가\n",
    "    train_bboxes.append(bbox_list)\n",
    "# print(len(train_bboxes))\n",
    "# 결과 출력 (예시)\n",
    "# print(train_bboxes[:5])  # 첫 5개 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# 모든 bboxes 데이터 처리\n",
    "valid_bboxes = []\n",
    "# print(len(valid_data))\n",
    "\n",
    "# 모든 bboxes 데이터 처리\n",
    "for bbox_str in valid_data[\"bboxes\"]:\n",
    "    bboxes = ast.literal_eval(bbox_str)  # 문자열을 실제 리스트로 변환\n",
    "    bbox_list = []  # 해당 index에 대한 모든 bboxes를 저장할 리스트\n",
    "\n",
    "    # 각 bbox에 대해 처리\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        bbox_list.append([x, y, w, h])  # 해당 index의 모든 bbox를 하나의 리스트에 저장\n",
    "\n",
    "    # 하나의 index에 대한 bbox 리스트를 train_bboxes에 추가\n",
    "    valid_bboxes.append(bbox_list)\n",
    "# print(len(valid_bboxes))\n",
    "# 결과 출력 (예시)\n",
    "# print(valid_bboxes[:5])  # 첫 5개 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "num = 0\n",
    "# 저장할 파일 경로\n",
    "data_save_path = f'./data/sampled_data{num}.pkl'\n",
    "\n",
    "# 데이터 저장 함수\n",
    "\n",
    "\n",
    "def save_data(file_path, x, y):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump({'x': x, 'y': y}, f)\n",
    "    print(f\"데이터가 '{file_path}'에 저장되었습니다.\")\n",
    "\n",
    "# 데이터 로드 함수\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"데이터가 '{file_path}'에서 로드되었습니다.\")\n",
    "    return data['x'], data['y']\n",
    "\n",
    "# 데이터 로드 후 샘플링과 분할 처리 (최초 1회 실행)\n",
    "\n",
    "\n",
    "def process_and_save_data():\n",
    "    # 이미지와 라벨 데이터 생성 (예시 코드 연결)\n",
    "    # x와 y는 이미지를 처리한 결과\n",
    "    x_sampled, y_sampled = resample(x, y, n_samples=100, random_state=42)\n",
    "    num += 1\n",
    "    # 데이터 저장\n",
    "    save_data(data_save_path, x_sampled, y_sampled)\n",
    "\n",
    "    return x_sampled, y_sampled\n",
    "\n",
    "# 데이터 로드 및 분할\n",
    "\n",
    "\n",
    "def load_and_split_data(file_path):\n",
    "    x_sampled, y_sampled = load_data(file_path)\n",
    "\n",
    "    # 데이터 분할\n",
    "    x_training, x_test, y_training, y_test = train_test_split(\n",
    "        x_sampled, y_sampled, test_size=0.2, shuffle=True, stratify=y_sampled, random_state=34\n",
    "    )\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "        x_training, y_training, test_size=0.2, shuffle=True, stratify=y_training, random_state=34\n",
    "    )\n",
    "\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "# 데이터 처리 및 저장 (최초 1회 실행)\n",
    "# x_sampled, y_sampled = process_and_save_data()\n",
    "\n",
    "\n",
    "# 저장된 데이터 로드 및 분할\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = load_and_split_data(\n",
    "    data_save_path)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"x_train.shape: {x_train.shape}\")\n",
    "print(f\"x_valid.shape: {x_valid.shape}\")\n",
    "print(f\"x_test.shape: {x_test.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "print(f\"y_valid.shape: {y_valid.shape}\")\n",
    "print(f\"y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# data sampling\n",
    "x_sampled, y_sampled = resample(x, y, n_samples=100, random_state=42)\n",
    "\n",
    "print(x_sampled.shape)\n",
    "print(y_sampled.shape)\n",
    "\n",
    "\n",
    "# data split\n",
    "x_training, x_test, y_training, y_test = train_test_split(\n",
    "    x_sampled, y_sampled, test_size=0.2, shuffle=True, stratify=y_sampled, random_state=34)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_training, y_training, test_size=0.2, shuffle=True, stratify=y_training, random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "model = YOLO(\"yolov8s.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 감소 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.grid()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "pred=model(y_test)\n",
    "\n",
    "\n",
    "# 혼동 행렬\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=pred)\n",
    "print('혼동 행렬: ', confmat)\n",
    "\n",
    "\n",
    "# 정확도\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=pred)\n",
    "print('정확도: ', accuracy)\n",
    "\n",
    "\n",
    "# 정밀도(precision)\n",
    "precision = precision_score(y_true=y_test, y_pred=pred)\n",
    "print('정밀도: ', precision)\n",
    "\n",
    "\n",
    "# 재현율(recall)\n",
    "recall = recall_score(y_true=y_test, y_pred=pred)\n",
    "print('재현율: ', recall)\n",
    "\n",
    "\n",
    "# roc auc\n",
    "fpr, tpr, _ = roc_curve(y_true=y_test, y_pred=pred)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('auc 점수: ', roc_auc_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
