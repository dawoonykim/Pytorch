{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7381\n",
      "[['./data/data/source_data/bumper/scratch\\\\205_101_10_0107f873-8e8a-43d6-94c5-703a77b87e08.jpg'\n",
      "  '1']\n",
      " ['./data/data/source_data/bumper/scratch\\\\205_101_10_01ba8ed7-8669-4af9-ad2f-7c73a124e769.jpg'\n",
      "  '1']\n",
      " ['./data/data/source_data/bumper/scratch\\\\205_101_10_0232027f-bfd3-460b-b92d-b14537879e9a.jpg'\n",
      "  '1']\n",
      " ...\n",
      " ['./data/data/source_data/frame/Seam_failure\\\\207_212_20_ff60575c-e8ea-4308-99ba-9ab01930c37a.jpg'\n",
      "  '0']\n",
      " ['./data/data/source_data/frame/Seam_failure\\\\207_212_20_ff8e6b23-6f57-47d2-b6c2-4fd4eb50e9f7.jpg'\n",
      "  '0']\n",
      " ['./data/data/source_data/frame/Seam_failure\\\\207_212_20_ffa0491f-762f-41be-8040-007d56f2d01f.jpg'\n",
      "  '0']]\n"
     ]
    }
   ],
   "source": [
    "data_bumper = np.genfromtxt('./data/data/output/bumper/bumper_data.csv',\n",
    "                            delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_bumper = np.delete(data_bumper, 0, axis=0)\n",
    "\n",
    "data_door_ed = np.genfromtxt(\n",
    "    './data/data/output/door/door_ed_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_door_ed = np.delete(data_door_ed, 0, axis=0)\n",
    "data_door_scratch = np.genfromtxt(\n",
    "    './data/data/output/door/door_scratch_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_door_scratch = np.delete(data_door_scratch, 0, axis=0)\n",
    "\n",
    "data_fender = np.genfromtxt('./data/data/output/fender/fender_ed_data.csv',\n",
    "                            delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_fender = np.delete(data_fender, 0, axis=0)\n",
    "\n",
    "data_frame_ed = np.genfromtxt(\n",
    "    './data/data/output/frame/frame_ed_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_ed = np.delete(data_frame_ed, 0, axis=0)\n",
    "data_frame_hd = np.genfromtxt(\n",
    "    './data/data/output/frame/frame_hd_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_hd = np.delete(data_frame_hd, 0, axis=0)\n",
    "data_frame_sealf = np.genfromtxt(\n",
    "    './data/data/output/frame/frame_sealf_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_sealf = np.delete(data_frame_sealf, 0, axis=0)\n",
    "data_frame_seamf = np.genfromtxt(\n",
    "    './data/data/output/frame/frame_seamf_data.csv', delimiter=',', dtype=None, encoding='UTF-8')\n",
    "data_frame_seamf = np.delete(data_frame_seamf, 0, axis=0)\n",
    "\n",
    "data_1 = np.array((data_bumper))\n",
    "data_2 = np.array((data_door_ed))\n",
    "data_3 = np.array((data_door_scratch))\n",
    "data_4 = np.array((data_fender))\n",
    "data_5 = np.array((data_frame_ed))\n",
    "data_6 = np.array((data_frame_hd))\n",
    "data_7 = np.array((data_frame_sealf))\n",
    "data_8 = np.array((data_frame_seamf))\n",
    "\n",
    "data = np.concatenate((data_1, data_2, data_3, data_4,\n",
    "                      data_5, data_6, data_7, data_8), axis=0)  # axis=0: 배치 축\n",
    "print(len(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4870 5643 3530 6822 5091  405 3672 3681  448 3901 6543 1897 3190 4416\n",
      " 4787 5852 5965 3613 2102 1619 6706  879 1847 3599 2649 6956 4307 4036\n",
      " 2245  768 1029 2784 2802 6944 6716  959 4040 2121 5397 6265 6495 6856\n",
      " 1460 5646 4122  663 1591 1843 5058 1817 3949  396  237   71 3792 3368\n",
      " 3671 5548 7366  137 6011  479 6708 6079 2543 2345 1410 3623 1869 5591\n",
      " 5856 7081  813 2685 5561 6665   71 2092 7266  461 6006 4592 2090 4920\n",
      " 5605 5524 5360 6074 4307 3157 4158 4486 1315 6014 2825  482 3334 2015\n",
      " 1890 5497 3774 1295 6705  762   12 5083 6555 1743 6305 2210 2234 1871\n",
      " 2588 5651 1265  157 5135 1765 6708 3398 2379 1169  542 6945 4562 2968\n",
      " 6089  185 3272 4268 6985 5975 6817 3065  698  689 4730 4485 1942  767\n",
      " 2194 5419  442 3427   87 7217 4997 1204 2272 1374 4677 2928 3633 4616\n",
      " 5206 5344 6469 1083 3287  383 3456 1227 1758 3958 3972 1211 5215 5215\n",
      " 1270 6700 5001 7239 4656 4520 2860 2635 5936 4796 6825 3318 2244 2504\n",
      " 1086 1241 5801 6763 2158 6709 4931  628 1552   10 5309 5382 1148 3519\n",
      " 2102 4545 3278 4112]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_num=200  #100개당 35초\n",
    "\n",
    "num=random.randint(len(data), size=data_num)\n",
    "\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행현황: 0.0%\n",
      "진행현황: 5.0%\n",
      "진행현황: 10.0%\n",
      "진행현황: 15.0%\n",
      "진행현황: 20.0%\n",
      "진행현황: 25.0%\n",
      "진행현황: 30.0%\n",
      "진행현황: 35.0%\n",
      "진행현황: 40.0%\n",
      "진행현황: 45.0%\n",
      "진행현황: 50.0%\n",
      "진행현황: 55.00000000000001%\n",
      "진행현황: 60.0%\n",
      "진행현황: 65.0%\n",
      "진행현황: 70.0%\n",
      "진행현황: 75.0%\n",
      "진행현황: 80.0%\n",
      "진행현황: 85.0%\n",
      "진행현황: 90.0%\n",
      "진행현황: 95.0%\n",
      "(200, 2000, 4000, 3)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "img_1 = Image.open(data[0, 0])\n",
    "\n",
    "a = np.array(img_1)\n",
    "x = np.expand_dims(a, axis=0)\n",
    "y = []\n",
    "\n",
    "for i, i2 in enumerate(num):\n",
    "    img = Image.open(data[i2, 0])\n",
    "    x_3 = np.array(img)\n",
    "    x_4 = np.expand_dims(x_3, axis=0)\n",
    "    x = np.concatenate((x, x_4), axis=0)  # axis=0: 배치 축\n",
    "    y.append(data[i2, 1])\n",
    "    if i % 10 == 0:\n",
    "        print(f'진행현황: {int(i/data_num*100)}%')\n",
    "\n",
    "x = np.delete(x, 0, axis=0)\n",
    "y = np.array(y).reshape(data_num, 1)\n",
    "# print(x)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2000, 4000, 3)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# data sampling\n",
    "x_sampled, y_sampled = resample(x, y, n_samples=100, random_state=42)\n",
    "\n",
    "print(x_sampled.shape)\n",
    "print(y_sampled.shape)\n",
    "\n",
    "\n",
    "# data split\n",
    "x_training, x_test, y_training, y_test = train_test_split(\n",
    "    x_sampled, y_sampled, test_size=0.2, shuffle=True, stratify=y_sampled, random_state=34)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_training, y_training, test_size=0.2, shuffle=True, stratify=y_training, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_training=x_training.astype(int)\n",
    "# x_training = torch.from_numpy(x_training)\n",
    "# x_test = x_test.astype(int)\n",
    "# x_test = torch.from_numpy(x_test)\n",
    "y_training = y_training.astype(int)\n",
    "y_training = torch.from_numpy(y_training)\n",
    "\n",
    "y_test = y_test.astype(int)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "x_valid = torch.from_numpy(x_valid)\n",
    "y_valid = y_valid.astype(int)\n",
    "y_valid = torch.from_numpy(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.astype(int)\n",
    "x_train=torch.from_numpy(x_train)\n",
    "y_train=y_train.astype(int)\n",
    "y_train=torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# print(type(x_training))\n",
    "# print(type(x_test))\n",
    "# print(type(y_training))\n",
    "# print(type(y_test))\n",
    "print(type(x_train))\n",
    "# print(type(x_valid))\n",
    "print(type(y_train))\n",
    "# print(type(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "  \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"데이터셋의 크기 반환\"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"주어진 인덱스에 대한 이미지와 레이블을 반환\"\"\"\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 이미지 데이터를 numpy 배열에서 PIL 이미지로 변환\n",
    "        image = Image.fromarray(image.astype(np.uint8))  # numpy 배열을 PIL 이미지로 변환\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # 이미지 변환 적용\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# CustomDataset으로 데이터셋 만들기\n",
    "train_dataset = CustomDataset(\n",
    "    images=x_train, labels=y_train, transform=transform)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    images=x_valid, labels=y_valid, transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetLikeCNN(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (skip): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv4 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv5 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Skip connection adjustment\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetLikeCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNetLikeCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(16, 32, stride=2),\n",
    "            ResidualBlock(32, 32)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(32, 64, stride=2),\n",
    "            ResidualBlock(64, 64),\n",
    "            ResidualBlock(64, 64)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            ResidualBlock(64, 128, stride=2),\n",
    "            ResidualBlock(128, 128),\n",
    "            ResidualBlock(128, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )\n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ResNetLikeCNN(num_classes=10)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[164], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# train_loader에서 가져오기\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 입력 데이터와 레이블을 device로 이동\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dawoo\\Desktop\\SF7\\coding\\PYTORCH\\pytorch-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\dawoo\\Desktop\\SF7\\coding\\PYTORCH\\pytorch-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\dawoo\\Desktop\\SF7\\coding\\PYTORCH\\pytorch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[161], line 22\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     19\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 이미지 데이터를 numpy 배열에서 PIL 이미지로 변환\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(np\u001b[38;5;241m.\u001b[39muint8))  \u001b[38;5;66;03m# numpy 배열을 PIL 이미지로 변환\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m     25\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)  \u001b[38;5;66;03m# 이미지 변환 적용\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "# 모델 학습\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (input, label) in enumerate(train_loader):  # train_loader에서 가져오기\n",
    "\n",
    "        # 입력 데이터와 레이블을 device로 이동\n",
    "        input = input.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input)  # 모델에 입력\n",
    "        loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # 학습률 스케줄러 업데이트\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"학습 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트하기\n",
    "correct = 0\n",
    "total = len(test_loader.dataset)\n",
    "with torch.no_grad():  # test는 기울기 계산 X\n",
    "    for (images, labels) in test_loader:\n",
    "        # 손상된 이미지가 반환된 경우 건너뛰기\n",
    "        if images is None:\n",
    "            continue\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)  # 이미지를 GPU로 이동\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 손실 감소 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.grid()\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "pred=model(y_test)\n",
    "\n",
    "\n",
    "# 혼동 행렬\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=pred)\n",
    "print('혼동 행렬: ', confmat)\n",
    "\n",
    "\n",
    "# 정확도\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=pred)\n",
    "print('정확도: ', accuracy)\n",
    "\n",
    "\n",
    "# 정밀도(precision)\n",
    "precision = precision_score(y_true=y_test, y_pred=pred)\n",
    "print('정밀도: ', precision)\n",
    "\n",
    "\n",
    "# 재현율(recall)\n",
    "recall = recall_score(y_true=y_test, y_pred=pred)\n",
    "print('재현율: ', recall)\n",
    "\n",
    "\n",
    "# roc auc\n",
    "fpr, tpr, _ = roc_curve(y_true=y_test, y_pred=pred)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('auc 점수: ', roc_auc_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
